#Corpus Segmentation with agSegmentSf.py

     '.source.python':

       'agSegmentSf':
         'prefix': 'agSegmentSf'
         'body': """
          # The script you use to segment your corpus files according to its acoustic features is called agSegmentSf.py. AgSegmentSf.py creates textfiles which denote the start and stop times of sound segments in a multi-segment audiofile. To segment a corpus file, cd into the AudioGuide1.5 folder and run the following command :

          python agSegmentSf.py "examples/lachenmann.aiff"

          # As a result of running this python script, AudioGuide1.5 automatically writes a textfile with the exact same name and path as the soundfile, but adding the extension '.txt' -- in this case: examples/lachenmann.aiff.txt

          # Cf. http://www.benhackbarth.com/audioGuide/docs_v1.6.html
          """

#Finessing Corpus Segmentation

       'agSegmentSf_flags':
         'prefix': 'agSegmentSf_flags'
         'body': """
         python agSegmentSf.py -t -30 -d 4 "examples/lachenmann.aiff"

         # sets the threshold to -30. it will produce less onsets then -40 (the default). also changes the drop dB value to 4 dB above the minimum amplitude found in the entire soundfile, likely leading to longer segments.

         python agSegmentSf.py -r 4 "examples/lachenmann.aiff"

         # changes the rise ratio from the default (1.1) to 4. This means that a frame's amplitude must be four times louder than the previous one to start a new segment

         # Cf. http://www.benhackbarth.com/audioGuide/docs_v1.6.html
         """
#Whole Directory Segmentation

       'agSegmentSf_MyDir':
         'prefix': 'agSegmentSf_myDir'
         'body': """
         # Note that to segment a whole directory of soundfiles, you may use wildcard characters in the bash shell, as in:

        python agSegmentSf.py mydir/*.aiff

        # create a segmentation file for each aiff file located in mydir/

        # Cf. http://www.benhackbarth.com/audioGuide/docs_v1.6.html

         """

#Concatenating with agConcatenate.py

       'agConcatenate':
         'prefix': 'agConcatenate'
         'body': """
          # Once you have segmented corpus soundfiles to your satisfaction, you are ready to call the concatenation script agConcatenate.py with a special AudioGuide1.5 options file as the first (and only) argument.

          python agConcatenate.py examples/01-simplest.py

          # ...which will use the options contained in ‘examples/01-simplest.py’ to parameterize the concatenative algorithm. In this options file you specify a target sound, the corpus sounds, and (if you like) lots of other options that parameterize the concatenative process. When run, the ‘agConcatenate.py’ script will perform the following operations:

          # Run an ircamdescriptor analysis of the soundfile in the TARGET variable (note: the analysis is only done once -- subsequent usages of this soundfile simply read data from disk. Analysis files are stored in a directory called ‘AudioGuide1.5/audioguide/data/’ in the AudioGuide1.5 folder. This directory can become quite large since these files are quite substantial in size. Removing this folder will cause all analysis files to be recomputed).

          # Segment the target sound according to your options file. An Audacity-style label file is created in a file called ‘output/tgtlabels.txt’ in the output directory.

          # Run an ircamdescriptor analysis of the soundfiles in the CORPUS variable (only the first time each of these files are used).

          # (If you’ve specified them) Remove corpus segments according to descriptor limitations (Nothing above a certain pitch, nothing below a certain dynamic, etc.).

          # Normalize target and corpus descriptor data according to your options file (see this discussion and the "norm" and "normmethod" in the section Descriptors and the d() object).

          # Go through each target segment one by one. Select corpus segment(s) to match each target segment according to the normalized descriptors and search passes in the SEARCH variable (see the section SEARCH variable and spass() object) of your options file. Control over the layering and superimposition of corpus sounds is specified in the SUPERIMPOSE variable (see the section The SUPERIMPOSE variable and si() object).

          # Write selected segments to a csound score called ‘output/output.csd’. (In addition to the csd file there are many other types of outputs (see the section Concatenation Output Files).

          # If you have csound, ‘output/output.csd’ is rendered with csound to create an audiofile called ‘output/output.aiff’.

          # If you have csound, automatic playback of ‘output/output.aiff’ at the command line.

          # The options file used by the concatenate script is a python file that defines a bunch of variables. Most variables are simply floats and strings. For instance, to change the path of the csound output sound file, add the following line to your options file:

          # CSOUND_RENDER_FILEPATH = '/path/to/the/file/i/want.aiff'

          # sets the path of the csound output aiff file

          # DESCRIPTOR_HOP_SIZE_SEC = 0.02049

          # change the analysis hop size

          # Cf. http://www.benhackbarth.com/audioGuide/docs_v1.6.html
          """

#agConcatenate interactive mode

       'agConcatenate_interactive_mode':
         'prefix': 'agConcatenate_interactive_mode'
         'body': """
          #As of version 1.6, agConcatenate.py can be run in "interactive mode" by adding the -i flag at runtime. The interactive mode runs agConcatenate.py as normal except that, after rendering and playing the concatenated output, the program stays open and monitors the loaded options file for changes. When the options file is modified and saved, agConcatenate.py will examine the changes and only rerun the parts of the program needed to create a new output. This makes auditioning->tweaking->auditioning the same options file much faster, especially when working with large corpi.

          # To run agConcatenate.py in interactive mode, add the -i flag:

           python agConcatenate.py examples/01-simplest.py -i

          # To exit interactive mode, type control-C.

          # Cf. http://www.benhackbarth.com/audioGuide/docs_v1.6.html
          """

#Corpus Segmentation with agGranulateSf.py

       'agGranulateSf':
         'prefix': 'agGranulateSf'
         'body': """
          # A script you can use to segment your corpus files for use with granular synthesis is called ‘agGranulateSf.py’. Like agSegmentSf.py, agGranulateSf.py creates textfiles which denote the start and stop times of sound segments in a multi-segment audiofile. Unlike agSegmentSf.py, this script chops up a soundfile into evenly size grains and provides a mechanism for adjusting grain overlap. To segment a corpus file, ‘cd’ into the AudioGuide1.5 folder and run the following command:

          python agGranulateSf.py examples/lachenmann.aiff

          # As a result of running this python script, AudioGuide1.5 automatically writes a textfile with the exact same name and path as the soundfile, but adding the extension '.txt' -- in this case: examples/lachenmann.aiff.txt

          # It is important to note that, if you wish to window each grain with a fade in and fade out when concatenating, you will need to use the csf() onsetLen and offsetLen keyword arguments.

          csf('lachenmann.aiff', onsetLen='50%', offsetLen='50%')

          # Cf. http://www.benhackbarth.com/audioGuide/docs_v1.6.html
          """


############################################

# Descriptor Retrieval with agGetSfDescriptors.py

       'agGetSfDescriptors':
         'prefix': 'agGetSfDescriptors'
         'body': """
         # agGetSfDescriptors.py is a simple script that exports continuous descriptor values of a soundfile. The output format is a json dictionary. To use it simply call the script with the soundfile as the first argument and the output path as the second argument.

         python agGetSfDescriptors.py examples/lachenmann.aiff examples/lachenmann.json

         # Cf. http://www.benhackbarth.com/audioGuide/docs_v1.6.html
          """

############################################
#The TARGET Variable and tsf() object

       'tsf()':
         'prefix': 'tsf()'
         'body': """

          Target = tsf('${1:path_to_soundfile}', start=${2:0}, end=${3:file-length}, thresh=${4:-40}, offsetRise=${5:1.5}, offsetThreshAdd=${6:+12}, offsetThreshAbs=${7:-80}, scaleDb=${8:0}, minSegLen=${9:0.05}, maxSegLen=${10:1000}, midiPitchMethod='${11:composite}', stretch=${12:1}, segmentationFilepath=${13:None},multiriseBool=${14:False}, multirisePercentDev=${15:20},multiriseSteps=${16:5}, decompose={${17:}})

          # Cf. http://www.benhackbarth.com/audioGuide/docs_v1.6.html
          """

############################################
#The CORPUS Variable and csf() object

       'csf()':
         'prefix': 'csf()'
         'body': """

          csf(${2:"pathToFileOrDirectoryOfFiles"}, start=${3:None}, end=${4:None},
          includeTimes=[${5:}], excludeTimes=[${6:}], pitchfilter={${7:}}, limit=[${8:}],
          wholeFile=${9:False}, recursive=${10:True}, includeStr=${11:None}, excludeStr=${12:None},
          scaleDb=${13:0.0}, limitDur=${14:None}, clipDurationToTarget=${15:False},
          onsetLen=${16:0.01}, offsetLen="${17:30%}", midiPitchMethod="${18:composite}",
          transMethod=${19:None}, transQuantize=${20:0}, concatFileName=${21:None},
          allowRepetition=${22:True}, restrictRepetition=${23:0.5}, restrictOverlaps=${24:None}, restrictInTime=${25:0}, maxPercentTargetSegments=${26:None}, scaleDistance=${27:1}, superimposeRule=${28:None}, segmentationFile=${29:None}, segmentationExtension="${30:.txt}", envelopeSlope=${31:1}, wholeFileMinStart=${32:0},  wholeFileMaxEnd=${33:None}, metadata=[${34:}], instrTag=${35:None}, instrParams={${36:}})

          # Cf. http://www.benhackbarth.com/audioGuide/docs_v1.6.html
          """

##############################################
#Descriptors and the d() object

       'Descriptors':
         'prefix': 'd()'
         'body': """

          d('${1:audiodescriptor}', weight=${2:1}, norm=${3:2}, normmethod='${4:stddev}', distance='${5:euclidean}', limit=${6:False}, simultaneous=${7:None}, energyWeight=${8:False}, origin='${9:SEARCH}', neededBy=['${10:target}', '${11:corpus}'], packagename=${12:None})

          # Cf. http://www.benhackbarth.com/audioGuide/docs_v1.6.html
          """

###############################################
# SEARCH variable and spass() object

       'SEARCH_01':
         'prefix': 'spass()'
         'body': """

         # spass(method, list of descriptors, d1, d2, d3,...) + keywords.

         # Documented in 02-searching.py
         # Cf. http://www.benhackbarth.com/audioGuide/docs_v1.6.html

         SEARCH = [
           spass("${1:closest}",d("${2:centroid}"))
         ]

         # SEARCH = [
         #   spass(...),
         #   # first spass. the input is all valid corpus samples
         #
         #   spass(...),
         #   # second spass. the input is the output from the previous spass
         # ]

         """
#############################################

        'SEARCH_02':
           'prefix': 'spass(closest)'
           'body': """

           SEARCH = [
             spass("${1:closest}",d("${2:audiodescriptor}"))
           ]

           # Cf. http://www.benhackbarth.com/audioGuide/docs_v1.6.html
           """

#############################################

        'SEARCH_03':
           'prefix': 'spass(farthest)'
           'body': """

           SEARCH = [
             spass("${1:farthest}",d("${2:audiodescriptor}"))
           ]

           # Cf. http://www.benhackbarth.com/audioGuide/docs_v1.6.html
           """
#############################################

        'SEARCH_04':
           'prefix': 'spass(closest_percent)'
           'body': """

           SEARCH = [
             spass("${1:closest_percent}",d("${2:audiodescriptor}"), percent=${3:10})
           ]

           # Cf. http://www.benhackbarth.com/audioGuide/docs_v1.6.html
           """
#############################################


        'SEARCH_05':
           'prefix': 'spass(farthest_percent)'
           'body': """

           SEARCH = [
             spass("${1:farthest_percent}",d("${2:audiodescriptor}", percent=${3:10}))
           ]

           # Cf. http://www.benhackbarth.com/audioGuide/docs_v1.6.html
           """

#############################################

        'SEARCH_06':
           'prefix': 'spass(ratio_limit)'
           'body': """

           SEARCH = [

             spass("${1:ratio_limit}",d("${2:audiodescriptor}", minratio=${3:0.9}, maxratio=${4:1.1})
           ]

           # Cf. http://www.benhackbarth.com/audioGuide/docs_v1.6.html
           """

#############################################

        'SEARCH_07':
           'prefix': 'spass(parser)'
           'body': """

           SEARCH = [

             spass("${1:parser}", ${2:test}, ${3:submethod}, ${4:ifTrue}, ${5:ifFalse})
           ]

           # Cf. http://www.benhackbarth.com/audioGuide/docs_v1.6.html
           """

#############################################
#The SUPERIMPOSE variable and si() object

       'SUPERIMPOSE':
         'prefix': 'si()'
         'body': """

         SUPERIMPOSE = si(minSegment=${1:None}, maxSegment=${2:None}, minFrame=${3:None}, maxFrame=${4:None}, minOverlap=${5:None}, maxOverlap=${6:None}, overlapAmpThresh=${7:-70},  searchOrder='${8:power}',  subtractScale=${9:1}, subtractDur='${10:corpusDur}',  ampDur='${11:corpusDur}',  overlapDur='${12:corpusEffDur}',  calcMethod='${13:mixture}',  peakAlign=${14:False},  peakAlignEnvelope='${15:subtracted}', incr=${16:1})

         # Cf. http://www.benhackbarth.com/audioGuide/docs_v1.6.html
         # SUPERIMPOSE documented in 03-superimposition.py
         """

##############################################
#Creating Notated Scores
#score() and instr()

       'score()':
         'prefix': 'score()'
         'body': """


         # here, the corpus consists of pizzicato and arco string samples tagged with the string 'violin'

         CORPUS = [
         csf("pizzicato/", instrTag='violin', wholeFile=True),
         csf("arco/", instrTag='violin', wholeFile=True),
         ]

         # instruments specifies a score() consisting of a solo violin which is linked to both corpus items through the 'violin' instrTag.

         INSTRUMENTS = score(
         instr('violin'),
         tempo=${1:60},
         meter='${2:4/4}',

         )

         # Cf. http://www.benhackbarth.com/audioGuide/docs_v1.6.html
         """

##############################################
#

       'score_multi_instr()':
         'prefix': 'score_multi_instr()'
         'body': """

         # score() may have multiple instr()s with the same instrTag; this indicates that there are more than one of a certain type of instrument in the ensemble that can use the same corpus resources.

        CORPUS = [
        csf("pizzicato/", instrTag='violin', wholeFile=True),
        csf("arco/", instrTag='violin', wholeFile=True),
        csf("pizzicato/", instrTag='viola', wholeFile=True),
        csf("arco/", instrTag='viola', wholeFile=True),
        csf("pizzicato/", instrTag='cello', wholeFile=True),
        ]

        INSTRUMENTS = score(
        instr('violin'),
        instr('violin'),
        instr('viola', clef='Alto'),
        instr('cello', clef='F'), # only has pizz
        )

         # Cf. http://www.benhackbarth.com/audioGuide/docs_v1.6.html
         """

############################################
#instr()

       'instr()':
         'prefix': 'instr()'
         'body': """

         # the instr() object has keywords that affect the instrument's behavior and how the instrument is translated into musical notation.

         instr('instrTag', temporal_mode=${1:'sus'}, minspeed=${2:0.075}, interval_limit_breakpoints=[${3:}], interval_limit_range_per_sec=${4:None}, polyphony_minspeed=${5:None}, polyphony_max_voices=${6:1}, polyphony_max_range=${7:None}, polyphony_min_range=${8:None}, polyphony_permit_unison=${9:False}, polyphony_max_db_difference=${10:4}, technique_switch_delay_map=[${11:}], clef='${12:G}', key='${13:CM}', dynamics=(${14:'pp', 'p', 'mp', 'mf', 'f', 'ff'})))

         # Cf. http://www.benhackbarth.com/audioGuide/docs_v1.6.html
         """
###########################################
# custom slot assignment:

       'INSTRUMENTS_BACH_SLOTS_DICT':
         'prefix': 'INSTRUMENTS_BACH_SLOTS_DICT'
         'body': """

         INSTRUMENTS_BACH_SLOTS_DICT = {1: '${1:technique}', 2: '${2:fullpath}', 3: '${3:sfskiptime}', 10: '${4:noisiness-seg}', 11: '${5:centroid}'}

         # Cf. http://www.benhackbarth.com/audioGuide/docs_v1.6.html
         """

###########################################

#defaults.py'

##############  OUTPUT FILES  #############

# CSOUND_CSD_FILEPATH = 'output/output.csd'

       'CSOUND_CSD_FILEPATH':
         'prefix': 'CSOUND_CSD_FILEPATH'
         'body': 'CSOUND_CSD_FILEPATH = "${1:filepath/filename.csd}"'

# CSOUND_RENDER_FILEPATH = 'output/output.aiff'

       'CSOUND_RENDER_FILEPATH':
         'prefix': 'CSOUND_RENDER_FILEPATH'
         'body': 'CSOUND_RENDER_FILEPATH = "${1:filepath/filename.aiff}"'

# HTML_LOG_FILEPATH = 'output/log.html'

       'HTML_LOG_FILEPATH':
         'prefix': 'HTML_LOG_FILEPATH'
         'body': 'HTML_LOG_FILEPATH = "${1:filepath/filename.log.html}"'

# MIDI_FILEPATH = None # 'output/output.mid'

        'MIDI_FILEPATH':
          'prefix': 'MIDI_FILEPATH'
          'body': 'MIDI_FILEPATH = "${1:filepath/filename.mid}"'

# MIDIFILE_TEMPO = 60.

        'MIDIFILE_TEMPO':
          'prefix': 'MIDIFILE_TEMPO'
          'body': 'MIDIFILE_TEMPO = "${1:60.}"'

# TARGET_SEGMENT_LABELS_FILEPATH = 'output/targetlabels.txt'

        'TARGET_SEGMENT_LABELS_FILEPATH':
          'prefix': 'TARGET_SEGMENT_LABELS_FILEPATH'
          'body': 'TARGET_SEGMENT_LABELS_FILEPATH = "${1:filepath/filename.targetlabels.txt}"'

# TARGET_SEGMENTATION_GRAPH_FILEPATH = None #'output/targetlabels.jpg'

        'TARGET_SEGMENTATION_GRAPH_FILEPATH':
          'prefix': 'TARGET_SEGMENTATION_GRAPH_FILEPATH'
          'body': 'TARGET_SEGMENTATION_GRAPH_FILEPATH = "${1:filepath/filename.targetlbels.jpg}"'

# OUTPUT_LABEL_FILEPATH = 'output/outputlabels.txt'

        'OUTPUT_LABEL_FILEPATH':
          'prefix': 'OUTPUT_LABEL_FILEPATH'
          'body': 'OUTPUT_LABEL_FILEPATH = "${1:filepath/filename.labels.txt}"'

# LISP_OUTPUT_FILEPATH = None #'output/output.lisp.txt'

        'LISP_OUTPUT_FILEPATH':
          'prefix': 'LISP_OUTPUT_FILEPATH'
          'body': 'LISP_OUTPUT_FILEPATH = "${1:filepath/filename.lisp.txt}"'


# DATA_FROM_SEGMENTATION_FILEPATH = None #'output/datafromsegmentation.txt'

        'DATA_FROM_SEGMENTATION_FILEPATH':
          'prefix': 'DATA_FROM_SEGMENTATION_FILEPATH'
          'body': 'DATA_FROM_SEGMENTATION_FILEPATH = None
          #"${1:filepath/filename.datafromsegmentation.txt}"'


# DICT_OUTPUT_FILEPATH = 'output/output.json'

       'DICT_OUTPUT_FILEPATH':
         'prefix': 'DICT_OUTPUT_FILEPATH'
         'body': 'DICT_OUTPUT_FILEPATH = "${1:filepath/filename.json}"'

# MAXMSP_OUTPUT_FILEPATH = 'output/output.maxmsp.json'

       'MAXMSP_OUTPUT_FILEPATH':
         'prefix': 'MAXMSP_OUTPUT_FILEPATH'
         'body': 'MAXMSP_OUTPUT_FILEPATH = "${1:filepath/filename.maxmsp.json}"'

# SCORE_OUTPUT_FILEPATH = 'output/bachroll.txt'

       'BACH_OUTPUT_FILEPATH':
         'prefix': 'BACH_OUTPUT_FILEPATH'
         'body': 'BACH_OUTPUT_FILEPATH = "${1:filepath/filename.bachroll.txt}"'

#TARGET_DESCRIPTORS_FILEPATH = None # 'output/targetdescriptors.json'

        'TARGET_DESCRIPTORS_FILEPATH':
          'prefix': 'TARGET_DESCRIPTORS_FILEPATH'
          'body': 'TARGET_DESCRIPTORS_FILEPATH = "${1:filepath/filename.targetdescriptors.json}"'

#TARGET_PLOT_DESCRIPTORS_FILEPATH = None #'output/targetplot.jpg'

        'TARGET_PLOT_DESCRIPTORS_FILEPATH':
          'prefix': 'TARGET_PLOT_DESCRIPTORS_FILEPATH'
          'body': 'TARGET_PLOT_DESCRIPTORS_FILEPATH = "${1:filepath/filename.targetplot.jpg}"'

# CORPUS_SEGMENTED_FEATURES_JSON_FILEPATH = None

        'CORPUS_SEGMENTED_FEATURES_JSON_FILEPATH':
          'prefix': 'CORPUS_SEGMENTED_FEATURES_JSON_FILEPATH'
          'body': 'CORPUS_SEGMENTED_FEATURES_JSON_FILEPATH = None'


#
# ##########  CORPUS   #######
# SEARCH = []
# CORPUS_GLOBAL_ATTRIBUTES = {}

        'CORPUS_GLOBAL_ATTRIBUTES':
          'prefix': 'CORPUS_GLOBAL_ATTRIBUTES'
          'body': 'CORPUS_GLOBAL_ATTRIBUTES = {${1:}}'

# VOICE_PATTERN = []

        'VOICE_PATTERN':
          'prefix': 'VOICE_PATTERN'
          'body': 'VOICE_PATTERN = [${1:}]'

# VOICE_TO_ONSET_MAPPING = []

        'VOICE_TO_ONSET_MAPPING':
          'prefix': 'VOICE_TO_ONSET_MAPPING'
          'body': 'VOICE_TO_ONSET_MAPPING = [${1:}]'


# ROTATE_VOICES = False

        'ROTATE_VOICES':
          'prefix': 'ROTATE_VOICES'
          'body': 'ROTATE_VOICES = False'

# ORDER_CORPUS_BY_DESCRIPTOR = None

        'ORDER_CORPUS_BY_DESCRIPTOR':
          'prefix': 'ORDER_CORPUS_BY_DESCRIPTOR'
          'body': 'ORDER_CORPUS_BY_DESCRIPTOR = None'

# RESTRICT_CORPUS_SELECT_PERCENTAGE_BY_STRING = {}

        'RESTRICT_CORPUS_SELECT_PERCENTAGE_BY_STRING':
          'prefix': 'RESTRICT_CORPUS_SELECT_PERCENTAGE_BY_STRING'
          'body': 'RESTRICT_CORPUS_SELECT_PERCENTAGE_BY_STRING = {${1:}}'

# RESTRICT_CORPUS_OVERLAP_BY_STRING = {}

        'RESTRICT_CORPUS_OVERLAP_BY_STRING':
          'prefix': 'RESTRICT_CORPUS_OVERLAP_BY_STRING'
          'body': 'RESTRICT_CORPUS_OVERLAP_BY_STRING = {${1:}}'

# INSTRUMENTS = None
#
# #######  NORMALIZATION  #######
# NORMALIZATION_METHOD = 'standard'

        'NORMALIZATION_METHOD':
          'prefix': 'NORMALIZATION_METHOD'
          'body': 'NORMALIZATION_METHOD = "standard"'

# NORMALIZATION_DELTA_FREEDOM = 0 # 0=default stddev

        'NORMALIZATION_DELTA_FREEDOM':
          'prefix': 'NORMALIZATION_DELTA_FREEDOM'
          'body': 'NORMALIZATION_DELTA_FREEDOM = ${1:0} #0=default stddev'

# CLUSTER_MAPPING = {}

        'CLUSTER_MAPPING':
          'prefix': 'CLUSTER_MAPPING'
          'body': 'CLUSTER_MAPPING = {${1:}}'

#
# #######  CONCATENATE SELECTION  #######
# SUPERIMPOSE = si()
# ALWAYS_MAKE_COMPLETE_MATCHING_RESULTS = False

        'ALWAYS_MAKE_COMPLETE_MATCHING_RESULTS':
          'prefix': 'ALWAYS_MAKE_COMPLETE_MATCHING_RESULTS'
          'body': 'ALWAYS_MAKE_COMPLETE_MATCHING_RESULTS = False'

# RANDOMIZE_AMPLITUDE_FOR_SIM_SELECTION = False

        'RANDOMIZE_AMPLITUDE_FOR_SIM_SELECTION':
          'prefix': 'RANDOMIZE_AMPLITUDE_FOR_SIM_SELECTION'
          'body': 'RANDOMIZE_AMPLITUDE_FOR_SIM_SELECTION = False'

# OUTPUT_GAIN_DB = 0.

        'OUTPUT_GAIN_DB':
          'prefix': 'OUTPUT_GAIN_DB'
          'body': 'OUTPUT_GAIN_DB = ${1:0.}'

# RANDOM_SEED = None

        'RANDOM_SEED':
          'prefix': 'RANDOM_SEED'
          'body': 'RANDOM_SEED = None'


#DYNAMIC_TO_DECIBEL

        'DYNAMIC_TO_DECIBEL':
          'prefix': 'DYNAMIC_TO_DECIBEL'
          'body': """
          DYNAMIC_TO_DECIBEL (type=dict, default={'pp': -50, 'p': -40, 'mp': -34, 'mf': -24, 'f': -20, 'ff': -10})

          # This variable specifies the default decibel values for dynamic strings used by csf(scaleDb='filenamedyn')
          """

#FILENAMESTRING_TO_DYNAMICS

        'FILENAMESTRING_TO_DYNAMICS':
          'prefix': 'FILENAMESTRING_TO_DYNAMICS'
          'body': """
          FILENAMESTRING_TO_DYNAMICS (type=dict, default={})

          # User-defined strings for matching soundfile names with dynamics as in DYNAMIC_TO_DECIBEL. E.g. {'really loud': 'ff', 'loudish': 'f'}

          # Any filenames which match one these partial strings will be assigned the given dynamic, and then the decibel scalar found in DYNAMIC_TO_DECIBEL will be used if scaleDb='filenamedyn'.
          """

# PRINT_SELECTION_HISTO

        'PRINT_SELECTION_HISTO':
          'prefix': 'PRINT_SELECTION_HISTO'
          'body': """
            PRINT_SELECTION_HISTO (type=bool, default=False)
            # if True will print robust information about corpus selection after concatenation. If false (the default) will add this information to the log file, if used.
          """




# PRINT_SIM_SELECTION_HISTO

        'PRINT_SIM_SELECTION_HISTO':
          'prefix': 'PRINT_SIM_SELECTION_HISTO'
          'body': """
            PRINT_SIM_SELECTION_HISTO (type=bool, default=False)

            # if True will print robust information about corpus overlapping selection after concatenation. If false (the default) will add this information to the log file, if used.
          """




#
# #######  POST-CONCATENATION EVENT MANIPULATION  #######
# OUTPUTEVENT_ALIGN_PEAKS = False

        'OUTPUTEVENT_ALIGN_PEAKS':
          'prefix': 'OUTPUTEVENT_ALIGN_PEAKS'
          'body': 'OUTPUTEVENT_ALIGN_PEAKS = False'

# OUTPUTEVENT_TIME_STRETCH = 1.

        'OUTPUTEVENT_TIME_STRETCH':
          'prefix': 'OUTPUTEVENT_TIME_STRETCH'
          'body': 'OUTPUTEVENT_TIME_STRETCH = ${1:1.}'

# OUTPUTEVENT_TIME_ADD = 0.

        'OUTPUTEVENT_TIME_ADD':
          'prefix': 'OUTPUTEVENT_TIME_ADD'
          'body': 'OUTPUTEVENT_TIME_ADD = ${1:0.}'

# OUTPUTEVENT_QUANTIZE_TIME_INTERVAL = 0.25

        'OUTPUTEVENT_QUANTIZE_TIME_INTERVAL':
          'prefix': 'OUTPUTEVENT_QUANTIZE_TIME_INTERVAL'
          'body': 'OUTPUTEVENT_QUANTIZE_TIME_INTERVAL = ${1:0.25}'

# OUTPUTEVENT_QUANTIZE_TIME_METHOD = None # snapToGrid | medianAggregate

        'OUTPUTEVENT_QUANTIZE_TIME_METHOD':
          'prefix': 'OUTPUTEVENT_QUANTIZE_TIME_METHOD'
          'body': 'OUTPUTEVENT_QUANTIZE_TIME_METHOD = None #snapToGrid | medianAggregate'

# OUTPUTEVENT_DURATION_SELECT = 'cps' # cps | tgt

        'OUTPUTEVENT_DURATION_SELECT':
          'prefix': 'OUTPUTEVENT_DURATION_SELECT'
          'body': 'OUTPUTEVENT_DURATION_SELECT = "cps" #cps | tgt'

# OUTPUTEVENT_DURATION_MIN = None

        'OUTPUTEVENT_DURATION_MIN':
          'prefix': 'OUTPUTEVENT_DURATION_MIN'
          'body': 'OUTPUTEVENT_DURATION_MIN = None'

# OUTPUTEVENT_DURATION_MAX = None

        'OUTPUTEVENT_DURATION_MAX':
          'prefix': 'OUTPUTEVENT_DURATION_MAX'
          'body': 'OUTPUTEVENT_DURATION_MAX = None'

# OUTPUTEVENT_CLASSIFY = {'numberClasses': 0, 'descriptors': ['mfcc1-seg', 'mfcc2-seg', 'mfcc3-seg', 'mfcc4-seg']} # only classifies if numberClasses >= 2

        'OUTPUTEVENT_CLASSIFY':
          'prefix': 'OUTPUTEVENT_CLASSIFY'
          'body': 'OUTPUTEVENT_CLASSIFY = {"numberClasses": ${1:0}, "descriptors": ["mfcc1-seg", "mfcc2-seg", "mfcc3-seg", "mfcc4-seg"]} # only classifies if numberClasses >= 2'

#
# ############  CSOUND RENDERING  ############
# CSOUND_SR = 48000

        'CSOUND_SR':
          'prefix': 'CSOUND_SR'
          'body': 'CSOUND_SR = ${1:48000}'

# CSOUND_KSMPS = 128

        'CSOUND_KSMPS':
          'prefix': 'CSOUND_KSMPS'
          'body': 'CSOUND_KSMPS = ${1:128}'

# CSOUND_BITS = 16

        'CSOUND_BITS':
          'prefix': 'CSOUND_BITS'
          'body': 'CSOUND_BITS = ${1:16}'

# CSOUND_CHANNEL_RENDER_METHOD = "corpusmax" # corpusmax | stereo | targetoutputmix | oneChannelPerVoice | oneChannelPerOverlap

       'CSOUND_CHANNEL_RENDER_METHOD':
         'prefix': 'CSOUND_CHANNEL_RENDER_METHOD'
         'body': 'CSOUND_CHANNEL_RENDER_METHOD = "targetoutputmix"
         # corpusmax | stereo | targetoutputmix | oneChannelPerVoice | oneChannelPerOverla'


# CSOUND_STRETCH_CORPUS_TO_TARGET_DUR = None # None | transpose | pv

        'CSOUND_STRETCH_CORPUS_TO_TARGET_DUR':
          'prefix': 'CSOUND_STRETCH_CORPUS_TO_TARGET_DUR'
          'body': 'CSOUND_STRETCH_CORPUS_TO_TARGET_DUR = None #None | transpose | pv '

# CSOUND_PLAY_RENDERED_FILE = True

        'CSOUND_PLAY_RENDERED_FILE':
          'prefix': 'CSOUND_PLAY_RENDERED_FILE'
          'body': 'CSOUND_PLAY_RENDERED_FILE = True'

# CSOUND_NORMALIZE = False

        'CSOUND_NORMALIZE':
          'prefix': 'CSOUND_NORMALIZE'
          'body': 'CSOUND_NORMALIZE = False'

# CSOUND_NORMALIZE_PEAK_DB = -3

        'CSOUND_NORMALIZE_PEAK_DB':
          'prefix': 'CSOUND_NORMALIZE_PEAK_DB'
          'body': 'CSOUND_NORMALIZE_PEAK_DB = ${1:-3}'

#
# ################  DESCRIPTOR COMPUTATION SETTINGS  ################
# DESCRIPTOR_OVERRIDE_DATA_PATH = None

        'DESCRIPTOR_OVERRIDE_DATA_PATH':
          'prefix': 'DESCRIPTOR_OVERRIDE_DATA_PATH'
          'body': 'DESCRIPTOR_OVERRIDE_DATA_PATH = None'

# DESCRIPTOR_FORCE_ANALYSIS = False

        'DESCRIPTOR_FORCE_ANALYSIS':
          'prefix': 'DESCRIPTOR_FORCE_ANALYSIS'
          'body': 'DESCRIPTOR_FORCE_ANALYSIS = False'

# DESCRIPTOR_WIN_SIZE_SEC = 0.04096

        'DESCRIPTOR_WIN_SIZE_SEC':
          'prefix': 'DESCRIPTOR_WIN_SIZE_SEC'
          'body': 'DESCRIPTOR_WIN_SIZE_SEC = ${1:0.04096}'

# DESCRIPTOR_HOP_SIZE_SEC = 0.01024

        'DESCRIPTOR_HOP_SIZE_SEC':
          'prefix': 'DESCRIPTOR_HOP_SIZE_SEC'
          'body': 'DESCRIPTOR_HOP_SIZE_SEC = ${1:0.01024}'

# DESCRIPTOR_ENERGY_ENVELOPE_HOP_SEC = 0.005

        'DESCRIPTOR_ENERGY_ENVELOPE_HOP_SEC':
          'prefix': 'DESCRIPTOR_ENERGY_ENVELOPE_HOP_SEC'
          'body': 'DESCRIPTOR_ENERGY_ENVELOPE_HOP_SEC = ${1:0.005}'

# # ircamdescriptor
# IRCAMDESCRIPTOR_RESAMPLE_RATE = 12500

        'IRCAMDESCRIPTOR_RESAMPLE_RATE':
          'prefix': 'IRCAMDESCRIPTOR_RESAMPLE_RATE'
          'body': 'IRCAMDESCRIPTOR_RESAMPLE_RATE = ${1:12500}'

# IRCAMDESCRIPTOR_WINDOW_TYPE = 'blackman'

        'IRCAMDESCRIPTOR_WINDOW_TYPE':
          'prefix': 'IRCAMDESCRIPTOR_WINDOW_TYPE'
          'body': 'IRCAMDESCRIPTOR_WINDOW_TYPE = ${1:"blackman"}'

# IRCAMDESCRIPTOR_F0_MAX_ANALYSIS_FREQ = 5000

        'IRCAMDESCRIPTOR_F0_MAX_ANALYSIS_FREQ':
          'prefix': 'IRCAMDESCRIPTOR_F0_MAX_ANALYSIS_FREQ'
          'body': 'IRCAMDESCRIPTOR_F0_MAX_ANALYSIS_FREQ = ${1:5000}'

# IRCAMDESCRIPTOR_F0_MIN_FREQUENCY = 20

        'IRCAMDESCRIPTOR_F0_MIN_FREQUENCY':
          'prefix': 'IRCAMDESCRIPTOR_F0_MIN_FREQUENCY'
          'body': 'IRCAMDESCRIPTOR_F0_MIN_FREQUENCY = ${1:20}'

# IRCAMDESCRIPTOR_F0_MAX_FREQUENCY = 5000

        'IRCAMDESCRIPTOR_F0_MAX_FREQUENCY':
          'prefix': 'IRCAMDESCRIPTOR_F0_MAX_FREQUENCY'
          'body': 'IRCAMDESCRIPTOR_F0_MAX_FREQUENCY = ${1:5000}'

# IRCAMDESCRIPTOR_F0_AMP_THRESHOLD = 1

        'IRCAMDESCRIPTOR_F0_AMP_THRESHOLD':
          'prefix': 'IRCAMDESCRIPTOR_F0_AMP_THRESHOLD'
          'body': 'IRCAMDESCRIPTOR_F0_AMP_THRESHOLD = ${1:1}'

# IRCAMDESCRIPTOR_NUMB_MFCCS = 13

        'IRCAMDESCRIPTOR_NUMB_MFCCS':
          'prefix': 'IRCAMDESCRIPTOR_NUMB_MFCCS'
          'body': 'IRCAMDESCRIPTOR_NUMB_MFCCS = ${1:13}'

# # other binary locations - None means disabled, otherwise specify a full path
# SUPERVP_BIN = None

        'SUPERVP_BIN':
          'prefix': 'SUPERVP_BIN'
          'body': 'SUPERVP_BIN = ${"path_to_binary"}'

# PM2_BIN = None

        'PM2_BIN':
          'prefix': 'PM2_BIN'
          'body': 'PM2_BIN = ${"path_to_binary"}'

#
# ###############  USER INTERACTION / PRINTING  ##############
# SEARCH_PATHS = []

        'SEARCH_PATHS':
          'prefix': 'SEARCH_PATHS'
          'body': 'SEARCH_PATHS = [${1:}]'

# VERBOSITY = 2

        'VERBOSITY':
          'prefix': 'VERBOSITY'
          'body': 'VERBOSITY = ${1:2}'

# TARGET_SEGMENT_LABELS_INFO = 'logic'

        'TARGET_SEGMENT_LABELS_INFO':
          'prefix': 'TARGET_SEGMENT_LABELS_INFO'
          'body': 'TARGET_SEGMENT_LABELS_INFO = ${1:"logic"}'

# EXPERIMENTAL = {}

        'EXPERIMENTAL':
          'prefix': 'EXPERIMENTAL'
          'body': 'EXPERIMENTAL = {${1:}}'
